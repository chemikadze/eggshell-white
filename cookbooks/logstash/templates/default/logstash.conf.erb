input {
  tcp {
    codec => "json"
    mode => "server"
    host => "0.0.0.0"
    port => 8514
    ssl_enable => true
    ssl_cert => "/var/lib/logstash/server.pem"
    ssl_key => "/var/lib/logstash/server.key"
    ssl_verify => false
    type => "nxlog"
  }
  <% @inputs.each do |input_map| %>
    <% input_map.each do |input_type, input_body| %>
      <%= input_type %> {
        <% input_body.each do |key, value| %>
          <%= key %> => <%= value.inspect %>
        <% end %>
      }
    <% end %>
  <% end %>
}
filter {

  # for backward compatibility
  mutate {
    rename => [ "Message", "message" ]
  }

  date {
      match => [ "EventReceivedTime", "YYYY-MM-dd HH:mm:ss" ]
      remove_field => [ "EventReceivedTime" ]
  }

  date {
      match => [ "EventReceivedTimeMs", "YYYY-MM-dd HH:mm:ss", "YYYY-MM-dd HH:mm:ss.S", "YYYY-MM-dd HH:mm:ss.SS", "YYYY-MM-dd HH:mm:ss.SSS", "YYYY-MM-dd HH:mm:ss.SSSS", "YYYY-MM-dd HH:mm:ss.SSSSS", "YYYY-MM-dd HH:mm:ss.SSSSSS" ]
      remove_field => [ "EventReceivedTimeMs" ]
  }

  grok {
      # v1   cobalt-52aab45be4b0ef4e9b9e0a9b.applications.52d4de58e4b08ec56d58a714.workflow/jobid.stepid.stepname/filename.txt
      # v2   52d4de58e4b08ec56d58a714/jobid.stepid.stepname/filename.txt
      # init 52d4de58e4b08ec56d58a714/chef-init/filename.txt
      match => [ "FileName", "(cobalt-%{BASE16NUM:appId}\.applications\.%{BASE16NUM:instId}\.?%{DATA:componentId}|%{BASE16NUM:instId})/(%{DATA:jobId}\.%{DATA:stepId}\.%{DATA:stepname}|%{DATA:chefInit})/%{GREEDYDATA:filename}" ]
  }

  grok {
      match => [ "instId", "cobalt-%{BASE16NUM:appId}\.applications\.%{BASE16NUM:realInstId}\.?%{DATA:componentId}" ]
      add_tag => [ "parsedinstid" ]
  }

  if "parsedinstid" in [tags] {
    mutate {
      replace => [ "instId", "%{realInstId}" ]
      remove_tag => ["parsedinstid"]
      remove_field => ["realInstId"]
    }
  }

  grok {
    match => [ "chefInit", ".+" ]
    add_field => [ "jobId", "~%{chefInit}~"]
    add_field => [ "stepId", "~%{chefInit}~" ]
    add_field => [ "stepname", "~%{chefInit}~" ]
  }

  mutate {
    add_tag => "unprocessed"
  }

  if "unprocessed" in [tags] {
    grok { # chef logs
        # TIMESTAMP_ISO8601
        # [2013-12-11T18:21:19+00:00] INFO: Setting the run_list to ["recipe[chef-solo-extension]", "recipe[nxlog]"] from JSON
        remove_tag => [ "unprocessed" ]
        match => [ "message", "\[[^\]]+\] %{LOGLEVEL:Severity}: %{GREEDYDATA:MessageTxt}" ]
    }
  }

  if "unprocessed" in [tags] {
    grok { # chef client warnings
        remove_tag => [ "unprocessed" ]
        match => [ "message", "[/\w_%!$@:.,-]+:%{NUMBER}: %{DATA:Severity}: %{GREEDYDATA:MessageTxt}" ]
    }
  }

  # haproxy
  if "unprocessed" in [tags] {
    grok {
        remove_tag => [ "unprocessed" ]
        match => [ "message", "%{HAPROXYHTTP}" ]
        add_field => [ "Severity", "INFO" ]
        add_field => [ "MessageTxt", "%{message}" ]
        add_field => [ "filename", "%{FileName}" ]
        remove_field => [ "Stream" ]
    }
  }

  # tomcat 1
  if "unprocessed" in [tags] {
    grok {
        remove_tag => [ "unprocessed" ]
        match => [ "message", "%{LOGLEVEL:Severity}: %{GREEDYDATA:MessageTxt}" ]
        add_field => [ "filename", "%{FileName}" ]
        remove_field => [ "Stream" ]
    }
  }

  # tomcat 2
  if "unprocessed" in [tags] {
    grok {
        remove_tag => [ "unprocessed" ]
        add_tag => [ "customdatetime" ]
        match => [ "message", "(?<EventReceivedTime>%{MONTH} %{MONTHDAY}, %{YEAR} %{TIME} (AM|PM)) %{GREEDYDATA:MessageTxt}" ]
        add_field => [ "filename", "%{FileName}" ]
        add_field => [ "Severity", "INFO" ]
    }
  }

  # mysqld.log
  if "unprocessed" in [tags] {
    grok {
        remove_tag => [ "unprocessed" ]
        add_tag => [ "customdatetime" ]
        match => [ "message", "(?<EventReceivedTime>\d{2}%{MONTHNUM}%{MONTHDAY} %{TIME}) %{GREEDYDATA:MessageTxt}" ]
        add_field => [ "filename", "%{FileName}" ]
        add_field => [ "Severity", "INFO" ]
    }
  }

  if "customdatetime" in [tags] {
    date {
      remove_tag => [ "customdatetime" ]
      match => [ "EventReceivedTime", "MMM dd, YYYY hh:mm:ss aa", "yyMMdd HH:mm:ss" ]
      locale => "US"
      timezone => "UTC"
    }
  }

  if "unprocessed" in [tags] {
    grok { # other messages from stderr
      remove_tag => [ "unprocessed" ]
      match => [ "Stream", "stderr" ]
      add_field => [ "Severity", "INFO" ]
      add_field => [ "MessageTxt", "%{message}" ]
    }
  }

  if "unprocessed" in [tags] {
    grok { # other messages stdout
      remove_tag => [ "unprocessed" ]
      match => [ "Stream", "stdout" ]
      add_field => [ "Severity", "INFO" ]
      add_field => [ "MessageTxt", "%{message}" ]
    }
  }

  if "unprocessed" in [tags] {
    mutate { # messages from custom locations
      remove_tag => [ "unprocessed" ]
      add_field => [ "Severity", "INFO" ] # TODO: parse most common formats
      add_field => [ "filename", "%{FileName}" ]
      add_field => [ "MessageTxt", "%{message}" ]
    }
  }

  grok {
    match => [ "host", "%{IPORHOST:parsed_host}(:${POSINT})?" ]
  }

  mutate {
      replace => [ "@severity", "%{Severity}" ]
      replace => [ "@message", "%{MessageTxt}" ]
      replace => [ "@raw", "%{message}" ]
      replace => [ "host", "%{parsed_host}" ]
  }

  mutate {
      remove_field => [ "message", "Message", "MessageTxt", "Severity", "SourceModuleType", "SourceModuleName", "EventReceivedTime", "EventReceivedTimeMs", "FileName", "@source_path", "@source", "parsed_host" ]
      remove_tag => ["_grokparsefailure"]
  }

}
output {
  stdout { debug => true }
  elasticsearch {
      index => "logstash-%{+YYYY.MM.dd}"
      embedded => true
  }
}
